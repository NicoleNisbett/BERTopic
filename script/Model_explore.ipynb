{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for exploring BERTopic models\n",
    "Once the model is cleaned, use this notebook to explore the topics, documents and extract bigrams etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle    \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "import re\n",
    "from collections import Counter\n",
    "#from wordcloud import WordCloud\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadPath = \"/Users/ipinni/Library/CloudStorage/OneDrive-UniversityofLeeds/UKRI_Tweet_Data/completed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP20model = BERTopic.load(loadPath +\"COP20/COP20_Bert_model\", embedding_model = \"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP20model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loadPath +'COP20/COP20topics.list', 'rb') as config_list_file:   \n",
    "    COP20topics = pickle.load(config_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP21model = BERTopic.load(loadPath +\"COP21/COP21_Bert_model\", embedding_model = \"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loadPath +'COP21/COP21topics.list', 'rb') as config_list_file:   \n",
    "    COP21topics = pickle.load(config_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP22model = BERTopic.load(loadPath +\"COP22/COP22_Bert_model\", embedding_model = \"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loadPath +'COP22/COP22topics.list', 'rb') as config_list_file:   \n",
    "    COP22topics = pickle.load(config_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP23model = BERTopic.load(loadPath +\"COP23/COP23_Bert_model\", embedding_model = \"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loadPath +'COP23/COP23topics.list', 'rb') as config_list_file:   \n",
    "    COP23topics = pickle.load(config_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP24model = BERTopic.load(loadPath +\"COP24/COP24_Bert_model\", embedding_model = \"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loadPath +'COP24/COP24topics.list', 'rb') as config_list_file:   \n",
    "    COP24topics = pickle.load(config_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP25model = BERTopic.load(loadPath +\"COP25/COP25_Bert_model\", embedding_model = \"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loadPath +'COP25/COP25topics.list', 'rb') as config_list_file:   \n",
    "    COP25topics = pickle.load(config_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP26model = BERTopic.load(loadPath +\"COP26/COP26_Bert_model\", embedding_model = \"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loadPath +'COP26/COP26topics.list', 'rb') as config_list_file:   \n",
    "    COP26topics = pickle.load(config_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP23model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"FFF2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(version):\n",
    "\n",
    "    model = BERTopic.load(loadPath + version + \"/\" + version + \"_Bert_model\", embedding_model = \"all-mpnet-base-v2\")\n",
    "\n",
    "    with open(loadPath + version + \"/\" + version + \"topics.list\" ,'rb') as config_list_file:   \n",
    "        topics = pickle.load(config_list_file)\n",
    "\n",
    "    with open(loadPath + version + \"/\" + version + \"docs.list\", 'rb') as docs_list_file:   \n",
    "        docs = pickle.load(docs_list_file)\n",
    "\n",
    "    return(topics, docs, model)\n",
    "\n",
    "#topics, docs, model = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF2018topics, FFF2018docs, FFF2018model = get_data(version = \"FFF2018\")\n",
    "FFF2019topics, FFF2019docs, FFF2019model = get_data(version = \"FFF2019\")\n",
    "FFF2020topics, FFF2020docs, FFF2020model = get_data(version = \"FFF2020\")\n",
    "FFF2021topics, FFF2021docs, FFF2021model = get_data(version = \"FFF2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the probability distribution of a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize_distribution(probs[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the retweets to the final topic counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_counts(cleanTweets_file, model, topics):\n",
    "    #load clean tweets file\n",
    "    cleanTweets = pd.read_csv(cleanTweets_file,header = 0, index_col=0, dtype= {'tweet_id': 'str', 'text': 'str', 'like_count': 'float', 'retweet_count': 'float'}, lineterminator='\\n')\n",
    "    #extract retweets for each document\n",
    "    retweets = list(cleanTweets.retweet_count)\n",
    "    list_tuple = list(zip(topics,retweets))\n",
    "    #extract retweets for each topic\n",
    "    res = defaultdict(int)\n",
    "    for k, v in list_tuple:\n",
    "        res[k] += v\n",
    "    \n",
    "    for key, value in res.items():\n",
    "        if value != value:\n",
    "            res[key] = 0.0\n",
    "    #get original counts\n",
    "    freqs = model.get_topic_info().sort_values('Topic')\n",
    "    A = Counter(dict(res.items()))\n",
    "    B = Counter(dict(zip(freqs.Topic, freqs.Count)))\n",
    "    #combine with retweets and create new df\n",
    "    C = A + B\n",
    "    D = pd.DataFrame(C.items(), columns = ['Topic', 'FullCount']).sort_values('Topic')\n",
    "    E = pd.DataFrame(zip(D.Topic, D.FullCount, freqs.Name), columns= ['Topic', 'FullCount', 'Name'])\n",
    "    return(E)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP20counts = get_full_counts(loadPath + \"COP20/COP20CleanTweets.csv\", COP20model, COP20topics)\n",
    "COP20counts.to_csv(loadPath + \"COP20/COP20Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP21counts = get_full_counts(loadPath + \"COP21/COP21CleanTweets.csv\", COP21model, COP21topics)\n",
    "COP21counts.to_csv(loadPath + \"COP21/COP21Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP22counts = get_full_counts(loadPath + \"COP22/COP22CleanTweets.csv\", COP22model, COP22topics)\n",
    "COP22counts.to_csv(loadPath + \"COP22/COP22Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP22counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP23counts = get_full_counts(loadPath + \"COP23/COP23CleanTweets.csv\", COP23model, COP23topics)\n",
    "COP23counts.to_csv(loadPath + \"COP23/COP23Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP24counts = get_full_counts(loadPath + \"COP24/COP24CleanTweets.csv\", COP24model, COP24topics)\n",
    "COP24counts.to_csv(loadPath + \"COP24/COP24Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP25counts = get_full_counts(loadPath + \"COP25/COP25CleanTweets.csv\", COP25model, COP25topics)\n",
    "COP25counts.to_csv(loadPath + \"COP25/COP25Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP26counts = get_full_counts(loadPath + \"COP26/COP26CleanTweets.csv\", COP26model, COP26topics)\n",
    "COP26counts.to_csv(loadPath + \"COP26/COP26Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF2018counts = get_full_counts(loadPath + \"FFF2018/FFF2018CleanTweets.csv\", FFF2018model, FFF2018topics)\n",
    "FFF2018counts.to_csv(loadPath + \"FFF2018/FFF2018Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF2019counts = get_full_counts(loadPath + \"FFF2019/FFF2019CleanTweets.csv\", FFF2019model, FFF2019topics)\n",
    "FFF2019counts.to_csv(loadPath + \"FFF2019/FFF2019Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF2020counts = get_full_counts(loadPath + \"FFF2020/FFF2020CleanTweets.csv\", FFF2020model, FFF2020topics)\n",
    "FFF2020counts.to_csv(loadPath + \"FFF2020/FFF2020Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF2021counts = get_full_counts(loadPath + \"FFF2021/FFF2021CleanTweets.csv\", FFF2021model, FFF2021topics)\n",
    "FFF2021counts.to_csv(loadPath + \"FFF2021/FFF2021Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP23fig = COP23model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP23fig.write_html(loadPath + \"COP23/COP23Topics.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP22model.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP23model.get_topic(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity between documents and topics using Jensen Shannon/KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get topics similar to a search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.find_topics([\"youth\", 'greta', 'threat', 'human rights'], top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_docs = model.get_representative_docs()\n",
    "data = pd.DataFrame.from_dict(representative_docs, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs=model.topic_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.topic_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap=model2.umap_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.umap_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_data = umap.fit_transform(embs)\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = model.hdbscan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=clusterer.condensed_tree_\n",
    "clusters = tree._select_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = list([\"rt\",\"RT\", \"&\", \"amp\", \"&amp\", \"http\",\"https\", \"http://\", \"https://\", \"fav\", \"FAV\"])\n",
    "new_stopwords = frozenset(list(text.ENGLISH_STOP_WORDS) + my_stopwords)\n",
    "vectorizer = CountVectorizer(stop_words=new_stopwords, min_df=10)\n",
    "count_matrix = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix2 = vectorizer.fit_transform(words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf6053f8d2e71441c5a2b29091b986c73fa987783e9f91500c4af0264d6d40de"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('bertopic_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
